{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset\n",
    "\n",
    "The dataset is in .dat format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq</th>\n",
       "      <th>Angle</th>\n",
       "      <th>Chord</th>\n",
       "      <th>Velocity</th>\n",
       "      <th>Thickness</th>\n",
       "      <th>Sound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>123.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>121.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>119.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>117.151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freq  Angle   Chord  Velocity  Thickness    Sound\n",
       "0  1000    0.0  0.3048      71.3   0.002663  125.201\n",
       "1  1250    0.0  0.3048      71.3   0.002663  125.951\n",
       "2  1600    0.0  0.3048      71.3   0.002663  127.591\n",
       "3  2000    0.0  0.3048      71.3   0.002663  127.461\n",
       "4  2500    0.0  0.3048      71.3   0.002663  125.571\n",
       "5  3150    0.0  0.3048      71.3   0.002663  125.201\n",
       "6  4000    0.0  0.3048      71.3   0.002663  123.061\n",
       "7  5000    0.0  0.3048      71.3   0.002663  121.301\n",
       "8  6300    0.0  0.3048      71.3   0.002663  119.541\n",
       "9  8000    0.0  0.3048      71.3   0.002663  117.151"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_table(\"airfoil_self_noise.dat\", sep=\"\\s+\")\n",
    "dataset.columns= ['Freq', 'Angle', 'Chord', 'Velocity', 'Thickness','Sound']\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split\n",
    "\n",
    "Of course the train-test split could be done at the regression model declaration stage, but I like this way better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.2, random_state=8)\n",
    "test.reset_index(drop=True)\n",
    "xtrain = train.iloc[:, 0:-1]\n",
    "ytrain = train.iloc[:,-1]\n",
    "xtest = test.iloc[:, 0:-1]\n",
    "ytest = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_regressor = AdaBoostRegressor()\n",
    "ada_regressor.fit(xtrain, ytrain)\n",
    "ypred_ada = ada_regressor.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'loss': 'square', 'n_estimators': 80}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_regressor_ht = AdaBoostRegressor()\n",
    "ada_parameters = {'n_estimators': [50,80,120,150,200],\n",
    "                  'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.3, 0.5, 1],\n",
    "                  'loss': ['linear', 'square', 'exponential']}\n",
    "\n",
    "gridsearch_ada = GridSearchCV(ada_regressor_ht, param_grid=ada_parameters)\n",
    "\n",
    "ada_regression_model = gridsearch_ada.fit(xtrain,ytrain)\n",
    "ypred_ada_regression_model = gridsearch_ada.predict(xtest)\n",
    "\n",
    "ada_regression_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model performance\n",
    "\n",
    "Root Mean squared error has only explanatory value when compared to other models' RMSE and a better model has smaller RMSE, that means, that the standard deviation of the residuals are smaller, therefore it is a better fit. \n",
    "\n",
    "R-square however shows how much percentage of the dependent variable can be explained by the independent variable. R-squared also takes overfitting into consideration and does not necessarily show a better value if multiple dependent variables are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st model RMSE: 3.7886794453967996\n",
      "1st model R-square: 0.693462820012728\n",
      "2nd model RMSE: 3.730275958125457\n",
      "2nd model R-square: 0.702840679531579\n"
     ]
    }
   ],
   "source": [
    "# First model\n",
    "\n",
    "RMSE_ada = np.sqrt(mean_squared_error(ytest, ypred_ada))\n",
    "rsq2 = ada_regressor.score(xtest, ytest)\n",
    "print(\"1st model RMSE:\", RMSE_ada)\n",
    "print(\"1st model R-square:\",rsq2)\n",
    "\n",
    "# second model\n",
    "\n",
    "RMSE_ada_2 = np.sqrt(mean_squared_error(ytest, ypred_ada_regression_model))\n",
    "rsq2 = ada_regression_model.score(xtest, ytest)\n",
    "print(\"2nd model RMSE:\", RMSE_ada_2)\n",
    "print(\"2nd model R-square:\",rsq2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With cross validation we can test the performance of the model in a way that we split the data into 5 batches (batch size can be freely determined) and we test the performance 5 times - each time a different batch will be the test set while all the other batches are the training set.\n",
    "\n",
    "I only do cross validation for the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores:  [0.72973674 0.76485816 0.71478381 0.75103734 0.69913738]\n",
      "Mean CV Score:  0.7319106864632727\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(ada_regression_model, xtrain, ytrain, cv=5)\n",
    "print(\"CV Scores: \", scores)\n",
    "print(\"Mean CV Score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: with the help of the adaboost regressor there is chance to give a somewhat accurate prediction to the noise level given the independent variables, but under similar circumstances, the Random Forest regressor provided more accurate predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
