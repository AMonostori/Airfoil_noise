{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset.\n",
    "\n",
    "The dataset is in .dat format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Frequency  Angle   Chord  Velocity  Thickness    Sound\n",
      "0          1000    0.0  0.3048      71.3   0.002663  125.201\n",
      "1          1250    0.0  0.3048      71.3   0.002663  125.951\n",
      "2          1600    0.0  0.3048      71.3   0.002663  127.591\n",
      "3          2000    0.0  0.3048      71.3   0.002663  127.461\n",
      "4          2500    0.0  0.3048      71.3   0.002663  125.571\n",
      "...         ...    ...     ...       ...        ...      ...\n",
      "1497       2500   15.6  0.1016      39.6   0.052849  110.264\n",
      "1498       3150   15.6  0.1016      39.6   0.052849  109.254\n",
      "1499       4000   15.6  0.1016      39.6   0.052849  106.604\n",
      "1500       5000   15.6  0.1016      39.6   0.052849  106.224\n",
      "1501       6300   15.6  0.1016      39.6   0.052849  104.204\n",
      "\n",
      "[1502 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_table(\"airfoil_self_noise.dat\", sep=\"\\s+\")\n",
    "dataset.columns= ['Frequency', 'Angle', 'Chord', 'Velocity', 'Thickness','Sound']\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split\n",
    "\n",
    "Of course the train-test split could be done at the regression model declaration stage, but I like this way better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.2, random_state=8)\n",
    "test.reset_index(drop=True)\n",
    "xtrain = train.iloc[:, 0:-1]\n",
    "ytrain = train.iloc[:,-1]\n",
    "xtest = test.iloc[:, 0:-1]\n",
    "ytest = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestRegressor(random_state=34)\n",
    "rf_regressor.fit(xtrain,ytrain)\n",
    "ypred_rf = rf_regressor.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'max_features': 4, 'n_estimators': 300}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regressor_ht = RandomForestRegressor(random_state=34)\n",
    "parameters = {'n_estimators': [50,100,200,300],\n",
    "              'max_features': [2,4,5, 'auto'],\n",
    "              'max_depth': [3,5,8, None]                   \n",
    "              }\n",
    "\n",
    "gridsearch = GridSearchCV(rf_regressor_ht, param_grid=parameters)\n",
    "\n",
    "RF_model = gridsearch.fit(xtrain,ytrain)\n",
    "ypred_rf_ht = gridsearch.predict(xtest)\n",
    "\n",
    "RF_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model performance\n",
    "\n",
    "Root Mean squared error has only explanatory value when compared to other models' RMSE and a better model has smaller RMSE, that means, that the standard deviation of the residuals are smaller, therefore it is a better fit. \n",
    "\n",
    "R-square however shows how much percentage of the dependent variable can be explained by the independent variable. R-squared also takes overfitting into consideration and does not necessarily show a better value if multiple dependent variables are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st model RMSE: 1.6642913569028208\n",
      "1st model R-square: 0.9408484472228751\n",
      "2nd model RMSE: 1.6642913569028208\n",
      "2nd model R-square: 0.9460831447560455\n"
     ]
    }
   ],
   "source": [
    "# first model\n",
    "\n",
    "rmse_rf_1 = np.sqrt(mean_squared_error(ytest, ypred_rf))\n",
    "rsq2 = rf_regressor.score(xtest, ytest)\n",
    "print(\"1st model RMSE:\", rmse_rf_1)\n",
    "print(\"1st model R-square:\",rsq2)\n",
    "\n",
    "# second model\n",
    "\n",
    "rmse_rf_2 = np.sqrt(mean_squared_error(ytest, ypred_rf_ht))\n",
    "rsq2 = RF_model.score(xtest, ytest)\n",
    "print(\"2nd model RMSE:\", rmse_rf_1)\n",
    "print(\"2nd model R-square:\",rsq2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With cross validation we can test the performance of the model in a way that we split the data into 5 batches (batch size can be freely determined) and we test the performance 5 times - each time a different batch will be the test set while all the other batches are the training set.\n",
    "\n",
    "I only do cross validation for the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores:  [0.91230905 0.93212618 0.9268391  0.91968995 0.91286847]\n",
      "Mean CV Score:  0.9207665491599718\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=gridsearch.best_estimator_.n_estimators,\n",
    "max_features=gridsearch.best_estimator_.max_features,\n",
    "max_depth= gridsearch.best_estimator_.max_depth\n",
    ")\n",
    "\n",
    "scores = cross_val_score(rf_model, xtrain, ytrain, cv=5)\n",
    "print(\"CV Scores: \", scores)\n",
    "print(\"Mean CV Score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: with the help of the Random Forest regressor there is chance to give a quite accurate prediction to the noise level given the independent variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
